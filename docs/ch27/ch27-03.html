<!DOCTYPE HTML>
<html lang="vi" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Experiments - Statistics</title>


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../highlight.css">
        <link rel="stylesheet" href="../tomorrow-night.css">
        <link rel="stylesheet" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('light')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><li class="part-title">Part I: Design of Experiments</li><li class="chapter-item expanded "><a href="../ch01/ch01.html"><strong aria-hidden="true">1.</strong> Controlled Experiments</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../ch01/ch01-01.html"><strong aria-hidden="true">1.1.</strong> The Salk Vaccine Field Trial</a></li><li class="chapter-item expanded "><a href="../ch01/ch01-02.html"><strong aria-hidden="true">1.2.</strong> The Portacaval Shunt</a></li></ol></li><li class="chapter-item expanded "><a href="../ch02/ch02.html"><strong aria-hidden="true">2.</strong> Observational Studies</a></li><li class="chapter-item expanded affix "><li class="part-title">Part II: Descriptive Statistics</li><li class="chapter-item expanded "><a href="../ch03/ch03.html"><strong aria-hidden="true">3.</strong> The Histogram</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../ch03/ch03-01.html"><strong aria-hidden="true">3.1.</strong> Introduction</a></li><li class="chapter-item expanded "><a href="../ch03/ch03-02.html"><strong aria-hidden="true">3.2.</strong> Drawing a Histogram</a></li></ol></li><li class="chapter-item expanded "><a href="../ch04/ch04.html"><strong aria-hidden="true">4.</strong> The Average and the Standard Deviation</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../ch04/ch04-01.html"><strong aria-hidden="true">4.1.</strong> Introduction</a></li><li class="chapter-item expanded "><a href="../ch04/ch04-02.html"><strong aria-hidden="true">4.2.</strong> The Average</a></li><li class="chapter-item expanded "><a href="../ch04/ch04-03.html"><strong aria-hidden="true">4.3.</strong> The Average and the Histogram</a></li></ol></li><li class="chapter-item expanded "><a href="../ch05/ch05.html"><strong aria-hidden="true">5.</strong> The Normal Approximation for Data</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../ch05/ch05-01.html"><strong aria-hidden="true">5.1.</strong> The Normal Curve</a></li><li class="chapter-item expanded "><a href="../ch05/ch05-02.html"><strong aria-hidden="true">5.2.</strong> Finding Areas Under The Normal Curve</a></li><li class="chapter-item expanded "><a href="../ch05/ch05-03.html"><strong aria-hidden="true">5.3.</strong> The Normal Approximation For Data</a></li><li class="chapter-item expanded "><a href="../ch05/ch05-04.html"><strong aria-hidden="true">5.4.</strong> Percentiles</a></li><li class="chapter-item expanded "><a href="../ch05/ch05-05.html"><strong aria-hidden="true">5.5.</strong> Percentiles And The Normal Curve</a></li><li class="chapter-item expanded "><a href="../ch05/ch05-06.html"><strong aria-hidden="true">5.6.</strong> Change Of Scale</a></li><li class="chapter-item expanded "><a href="../ch05/ch05-07.html"><strong aria-hidden="true">5.7.</strong> Review Exercises</a></li><li class="chapter-item expanded "><a href="../ch05/ch05-08.html"><strong aria-hidden="true">5.8.</strong> Summary</a></li></ol></li><li class="chapter-item expanded "><a href="../ch06/ch06.html"><strong aria-hidden="true">6.</strong> Measurement Error</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../ch06/ch06-01.html"><strong aria-hidden="true">6.1.</strong> Introduction</a></li><li class="chapter-item expanded "><a href="../ch06/ch06-02.html"><strong aria-hidden="true">6.2.</strong> Chance Error</a></li><li class="chapter-item expanded "><a href="../ch06/ch06-03.html"><strong aria-hidden="true">6.3.</strong> Outliers</a></li><li class="chapter-item expanded "><a href="../ch06/ch06-04.html"><strong aria-hidden="true">6.4.</strong> Bias</a></li><li class="chapter-item expanded "><a href="../ch06/ch06-05.html"><strong aria-hidden="true">6.5.</strong> Review Exercises</a></li><li class="chapter-item expanded "><a href="../ch06/ch06-06.html"><strong aria-hidden="true">6.6.</strong> Special Revew Exercises</a></li><li class="chapter-item expanded "><a href="../ch06/ch06-07.html"><strong aria-hidden="true">6.7.</strong> Summary</a></li></ol></li><li class="chapter-item expanded "><a href="../ch07/ch07.html"><strong aria-hidden="true">7.</strong> Plotting Points and Lines</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../ch07/ch07-01.html"><strong aria-hidden="true">7.1.</strong> Reading Points of a Graph</a></li><li class="chapter-item expanded "><a href="../ch07/ch07-02.html"><strong aria-hidden="true">7.2.</strong> Plotting Points</a></li><li class="chapter-item expanded "><a href="../ch07/ch07-03.html"><strong aria-hidden="true">7.3.</strong> Slope and Intercept</a></li><li class="chapter-item expanded "><a href="../ch07/ch07-04.html"><strong aria-hidden="true">7.4.</strong> Plotting Lines</a></li><li class="chapter-item expanded "><a href="../ch07/ch07-05.html"><strong aria-hidden="true">7.5.</strong> The Algebraic Equation For a Line</a></li></ol></li><li class="chapter-item expanded "><li class="part-title">Part III: Correlation and Regression</li><li class="chapter-item expanded "><a href="../ch08/ch08.html"><strong aria-hidden="true">8.</strong> Correlation</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../ch08/ch08-01.html"><strong aria-hidden="true">8.1.</strong> The Scatter Diagram</a></li><li class="chapter-item expanded "><a href="../ch08/ch08-02.html"><strong aria-hidden="true">8.2.</strong> The Correlation Coefficient</a></li><li class="chapter-item expanded "><a href="../ch08/ch08-03.html"><strong aria-hidden="true">8.3.</strong> The SD Line</a></li><li class="chapter-item expanded "><a href="../ch08/ch08-04.html"><strong aria-hidden="true">8.4.</strong> Computing The Correlation Coefficient</a></li><li class="chapter-item expanded "><a href="../ch08/ch08-05.html"><strong aria-hidden="true">8.5.</strong> Review Exercises</a></li><li class="chapter-item expanded "><a href="../ch08/ch08-06.html"><strong aria-hidden="true">8.6.</strong> Summary</a></li></ol></li><li class="chapter-item expanded "><a href="../ch09/ch09.html"><strong aria-hidden="true">9.</strong> More about Correlation</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../ch09/ch09-01.html"><strong aria-hidden="true">9.1.</strong> Features of the Correlation Coefficient</a></li><li class="chapter-item expanded "><a href="../ch09/ch09-02.html"><strong aria-hidden="true">9.2.</strong> Changing SDs</a></li><li class="chapter-item expanded "><a href="../ch09/ch09-03.html"><strong aria-hidden="true">9.3.</strong> Some Exceptional Case</a></li><li class="chapter-item expanded "><a href="../ch09/ch09-04.html"><strong aria-hidden="true">9.4.</strong> Ecological Correlations</a></li><li class="chapter-item expanded "><a href="../ch09/ch09-05.html"><strong aria-hidden="true">9.5.</strong> Association is Not Causation</a></li><li class="chapter-item expanded "><a href="../ch09/ch09-06.html"><strong aria-hidden="true">9.6.</strong> Review Exercises</a></li><li class="chapter-item expanded "><a href="../ch09/ch09-07.html"><strong aria-hidden="true">9.7.</strong> Summary</a></li></ol></li><li class="chapter-item expanded "><a href="../ch10/ch10.html"><strong aria-hidden="true">10.</strong> Regression</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../ch10/ch10-01.html"><strong aria-hidden="true">10.1.</strong> Introduction</a></li><li class="chapter-item expanded "><a href="../ch10/ch10-02.html"><strong aria-hidden="true">10.2.</strong> The Grapth of Averages</a></li><li class="chapter-item expanded "><a href="../ch10/ch10-03.html"><strong aria-hidden="true">10.3.</strong> The Regression Method for Individuals</a></li><li class="chapter-item expanded "><a href="../ch10/ch10-04.html"><strong aria-hidden="true">10.4.</strong> The Regression Fallacy</a></li><li class="chapter-item expanded "><a href="../ch10/ch10-05.html"><strong aria-hidden="true">10.5.</strong> There Are Two Regression Lines</a></li><li class="chapter-item expanded "><a href="../ch10/ch10-06.html"><strong aria-hidden="true">10.6.</strong> Review Exercises</a></li><li class="chapter-item expanded "><a href="../ch10/ch10-07.html"><strong aria-hidden="true">10.7.</strong> Summary</a></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">11.</strong> </div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">12.</strong> </div></li><li class="chapter-item expanded affix "><li class="part-title">Part IV: Probability</li><li class="chapter-item expanded "><a href="../ch13/ch13.html"><strong aria-hidden="true">13.</strong> What Are the Chances?</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../ch13/ch13-01.html"><strong aria-hidden="true">13.1.</strong> Introduction</a></li><li class="chapter-item expanded "><a href="../ch13/ch13-02.html"><strong aria-hidden="true">13.2.</strong> Conditional Probabilities</a></li><li class="chapter-item expanded "><a href="../ch13/ch13-03.html"><strong aria-hidden="true">13.3.</strong> The Multiplication Rule</a></li><li class="chapter-item expanded "><a href="../ch13/ch13-04.html"><strong aria-hidden="true">13.4.</strong> Independence</a></li><li class="chapter-item expanded "><a href="../ch13/ch13-05.html"><strong aria-hidden="true">13.5.</strong> The Collins Case</a></li><li class="chapter-item expanded "><a href="../ch13/ch13-06.html"><strong aria-hidden="true">13.6.</strong> Review Exercises</a></li><li class="chapter-item expanded "><a href="../ch13/ch13-07.html"><strong aria-hidden="true">13.7.</strong> Summary</a></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">14.</strong> </div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">15.</strong> </div></li><li class="chapter-item expanded affix "><li class="part-title">Part V: Change Variability</li><li class="chapter-item expanded "><a href="../ch16/ch16.html"><strong aria-hidden="true">16.</strong> The Law of Averages</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../ch16/ch16-01.html"><strong aria-hidden="true">16.1.</strong> What Does The Law of Averages Say?</a></li><li class="chapter-item expanded "><a href="../ch16/ch16-02.html"><strong aria-hidden="true">16.2.</strong> Chance Processes</a></li><li class="chapter-item expanded "><a href="../ch16/ch16-03.html"><strong aria-hidden="true">16.3.</strong> The Sum of Draws</a></li><li class="chapter-item expanded "><a href="../ch16/ch16-04.html"><strong aria-hidden="true">16.4.</strong> Making a Box Model</a></li><li class="chapter-item expanded "><a href="../ch16/ch16-05.html"><strong aria-hidden="true">16.5.</strong> Review Exercises</a></li><li class="chapter-item expanded "><a href="../ch16/ch16-06.html"><strong aria-hidden="true">16.6.</strong> Summary</a></li></ol></li><li class="chapter-item expanded "><a href="../ch17/ch17.html"><strong aria-hidden="true">17.</strong> The Expected Value and Standard Error</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../ch17/ch17-01.html"><strong aria-hidden="true">17.1.</strong> The Expected Value</a></li><li class="chapter-item expanded "><a href="../ch17/ch17-02.html"><strong aria-hidden="true">17.2.</strong> The Standard Error</a></li><li class="chapter-item expanded "><a href="../ch17/ch17-03.html"><strong aria-hidden="true">17.3.</strong> Using The Normal Curve</a></li><li class="chapter-item expanded "><a href="../ch17/ch17-04.html"><strong aria-hidden="true">17.4.</strong> A Short-Cut</a></li><li class="chapter-item expanded "><a href="../ch17/ch17-05.html"><strong aria-hidden="true">17.5.</strong> Classifying and Counting</a></li><li class="chapter-item expanded "><a href="../ch17/ch17-06.html"><strong aria-hidden="true">17.6.</strong> Review Exercises</a></li><li class="chapter-item expanded "><a href="../ch17/ch17-07.html"><strong aria-hidden="true">17.7.</strong> Postscript</a></li><li class="chapter-item expanded "><a href="../ch17/ch17-08.html"><strong aria-hidden="true">17.8.</strong> Summary</a></li></ol></li><li class="chapter-item expanded "><a href="../ch18/ch18.html"><strong aria-hidden="true">18.</strong> The Normal Approximation for Probability Histograms</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../ch18/ch18-01.html"><strong aria-hidden="true">18.1.</strong> Introduction</a></li><li class="chapter-item expanded "><a href="../ch18/ch18-02.html"><strong aria-hidden="true">18.2.</strong> Probability Histograms</a></li><li class="chapter-item expanded "><a href="../ch18/ch18-03.html"><strong aria-hidden="true">18.3.</strong> Probability Histograms and the Normal Curve</a></li><li class="chapter-item expanded "><a href="../ch18/ch18-04.html"><strong aria-hidden="true">18.4.</strong> The Normal Approximation</a></li><li class="chapter-item expanded "><a href="../ch18/ch18-05.html"><strong aria-hidden="true">18.5.</strong> The Scope of the Normal Approximation</a></li><li class="chapter-item expanded "><a href="../ch18/ch18-06.html"><strong aria-hidden="true">18.6.</strong> Conclusion</a></li><li class="chapter-item expanded "><a href="../ch18/ch18-07.html"><strong aria-hidden="true">18.7.</strong> Review Exercises</a></li><li class="chapter-item expanded "><a href="../ch18/ch18-08.html"><strong aria-hidden="true">18.8.</strong> Summary</a></li></ol></li><li class="chapter-item expanded "><li class="part-title">Part VI: Sampling</li><li class="chapter-item expanded "><a href="../ch19/ch19.html"><strong aria-hidden="true">19.</strong> Sample Surveys</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../ch19/ch19-01.html"><strong aria-hidden="true">19.1.</strong> Introduction</a></li><li class="chapter-item expanded "><a href="../ch19/ch19-02.html"><strong aria-hidden="true">19.2.</strong> The Literary Digest Poll</a></li><li class="chapter-item expanded "><a href="../ch19/ch19-03.html"><strong aria-hidden="true">19.3.</strong> The Year the Polls Elected Dewey</a></li><li class="chapter-item expanded "><a href="../ch19/ch19-04.html"><strong aria-hidden="true">19.4.</strong> Using Chance in Survey Work</a></li><li class="chapter-item expanded "><a href="../ch19/ch19-05.html"><strong aria-hidden="true">19.5.</strong> How Well do Probability Methods Work?</a></li><li class="chapter-item expanded "><a href="../ch19/ch19-06.html"><strong aria-hidden="true">19.6.</strong> A Closer Look at the Gallup Poll</a></li><li class="chapter-item expanded "><a href="../ch19/ch19-07.html"><strong aria-hidden="true">19.7.</strong> Telephone Surveys</a></li><li class="chapter-item expanded "><a href="../ch19/ch19-08.html"><strong aria-hidden="true">19.8.</strong> Chance Error and Bias</a></li><li class="chapter-item expanded "><a href="../ch19/ch19-09.html"><strong aria-hidden="true">19.9.</strong> Revew Exercises</a></li><li class="chapter-item expanded "><a href="../ch19/ch19-10.html"><strong aria-hidden="true">19.10.</strong> Summary</a></li></ol></li><li class="chapter-item expanded "><a href="../ch20/ch20.html"><strong aria-hidden="true">20.</strong> Chance Errors in Sampling</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../ch20/ch20-01.html"><strong aria-hidden="true">20.1.</strong> Introduction</a></li><li class="chapter-item expanded "><a href="../ch20/ch20-02.html"><strong aria-hidden="true">20.2.</strong> The Expected Value and Standard Error</a></li><li class="chapter-item expanded "><a href="../ch20/ch20-03.html"><strong aria-hidden="true">20.3.</strong> Using the Normal Curve</a></li><li class="chapter-item expanded "><a href="../ch20/ch20-04.html"><strong aria-hidden="true">20.4.</strong> The Correlation Factor</a></li><li class="chapter-item expanded "><a href="../ch20/ch20-05.html"><strong aria-hidden="true">20.5.</strong> The Gallup Poll</a></li><li class="chapter-item expanded "><a href="../ch20/ch20-06.html"><strong aria-hidden="true">20.6.</strong> Review Exercises</a></li><li class="chapter-item expanded "><a href="../ch20/ch20-07.html"><strong aria-hidden="true">20.7.</strong> Summary</a></li></ol></li><li class="chapter-item expanded "><a href="../ch21/ch21.html"><strong aria-hidden="true">21.</strong> The Accuracy of Percentages</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../ch21/ch21-01.html"><strong aria-hidden="true">21.1.</strong> Introduction</a></li><li class="chapter-item expanded "><a href="../ch21/ch21-02.html"><strong aria-hidden="true">21.2.</strong> Confidence Intervals</a></li><li class="chapter-item expanded "><a href="../ch21/ch21-03.html"><strong aria-hidden="true">21.3.</strong> Interpreting a Confidence Interval</a></li><li class="chapter-item expanded "><a href="../ch21/ch21-04.html"><strong aria-hidden="true">21.4.</strong> Caveat Emptor</a></li><li class="chapter-item expanded "><a href="../ch21/ch21-05.html"><strong aria-hidden="true">21.5.</strong> The Gallup Poll</a></li><li class="chapter-item expanded "><a href="../ch21/ch21-06.html"><strong aria-hidden="true">21.6.</strong> Review Exercises</a></li><li class="chapter-item expanded "><a href="../ch21/ch21-07.html"><strong aria-hidden="true">21.7.</strong> Summary</a></li></ol></li><li class="chapter-item expanded "><a href="../ch22/ch22.html"><strong aria-hidden="true">22.</strong> Measuring Employment and Unemployment</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../ch22/ch22-01.html"><strong aria-hidden="true">22.1.</strong> Introduction</a></li><li class="chapter-item expanded "><a href="../ch22/ch22-02.html"><strong aria-hidden="true">22.2.</strong> The Design of the Current Population Survey</a></li><li class="chapter-item expanded "><a href="../ch22/ch22-03.html"><strong aria-hidden="true">22.3.</strong> Carrying Out the Survey</a></li><li class="chapter-item expanded "><a href="../ch22/ch22-04.html"><strong aria-hidden="true">22.4.</strong> Weighting the Sample</a></li><li class="chapter-item expanded "><a href="../ch22/ch22-05.html"><strong aria-hidden="true">22.5.</strong> Standard Errors</a></li><li class="chapter-item expanded "><a href="../ch22/ch22-06.html"><strong aria-hidden="true">22.6.</strong> The Quality of the Data</a></li><li class="chapter-item expanded "><a href="../ch22/ch22-07.html"><strong aria-hidden="true">22.7.</strong> Bias</a></li><li class="chapter-item expanded "><a href="../ch22/ch22-08.html"><strong aria-hidden="true">22.8.</strong> Review Exercises</a></li><li class="chapter-item expanded "><a href="../ch22/ch22-09.html"><strong aria-hidden="true">22.9.</strong> Summary</a></li></ol></li><li class="chapter-item expanded "><a href="../ch23/ch23.html"><strong aria-hidden="true">23.</strong> The Accuracy of Averages</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../ch23/ch23-01.html"><strong aria-hidden="true">23.1.</strong> Introduction</a></li><li class="chapter-item expanded "><a href="../ch23/ch23-02.html"><strong aria-hidden="true">23.2.</strong> The Sample Average</a></li><li class="chapter-item expanded "><a href="../ch23/ch23-03.html"><strong aria-hidden="true">23.3.</strong> Which SE?</a></li><li class="chapter-item expanded "><a href="../ch23/ch23-04.html"><strong aria-hidden="true">23.4.</strong> A Reminder</a></li><li class="chapter-item expanded "><a href="../ch23/ch23-05.html"><strong aria-hidden="true">23.5.</strong> Review Exercises</a></li><li class="chapter-item expanded "><a href="../ch23/ch23-06.html"><strong aria-hidden="true">23.6.</strong> Special Review Exercises</a></li><li class="chapter-item expanded "><a href="../ch23/ch23-07.html"><strong aria-hidden="true">23.7.</strong> Summary and Overview</a></li></ol></li><li class="chapter-item expanded "><li class="part-title">Part VII: Chance Models</li><li class="chapter-item expanded "><a href="../ch24/ch24.html"><strong aria-hidden="true">24.</strong> A Model for Measurement Error</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../ch24/ch24-01.html"><strong aria-hidden="true">24.1.</strong> Estimating the Accuracy of an Average</a></li><li class="chapter-item expanded "><a href="../ch24/ch24-02.html"><strong aria-hidden="true">24.2.</strong> Chance Models</a></li><li class="chapter-item expanded "><a href="../ch24/ch24-03.html"><strong aria-hidden="true">24.3.</strong> The Gauss Model</a></li><li class="chapter-item expanded "><a href="../ch24/ch24-04.html"><strong aria-hidden="true">24.4.</strong> Conclusion</a></li><li class="chapter-item expanded "><a href="../ch24/ch24-05.html"><strong aria-hidden="true">24.5.</strong> Review Exercises</a></li><li class="chapter-item expanded "><a href="../ch24/ch24-06.html"><strong aria-hidden="true">24.6.</strong> Summary</a></li></ol></li><li class="chapter-item expanded "><a href="../ch25/ch25.html"><strong aria-hidden="true">25.</strong> Chance Models in Genetics</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../ch25/ch25-01.html"><strong aria-hidden="true">25.1.</strong> How Mendel Discovered Genes</a></li></ol></li><li class="chapter-item expanded "><li class="part-title">Part VIII: Tests of Significance</li><li class="chapter-item expanded "><a href="../ch26/ch26.html"><strong aria-hidden="true">26.</strong> Tests of Significance</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../ch26/ch26-01.html"><strong aria-hidden="true">26.1.</strong> Introduction</a></li><li class="chapter-item expanded "><a href="../ch26/ch26-02.html"><strong aria-hidden="true">26.2.</strong> The Null and The Alternative</a></li><li class="chapter-item expanded "><a href="../ch26/ch26-03.html"><strong aria-hidden="true">26.3.</strong> Test Statistics and Significance Levels</a></li><li class="chapter-item expanded "><a href="../ch26/ch26-04.html"><strong aria-hidden="true">26.4.</strong> Making a Test of Significance</a></li><li class="chapter-item expanded "><a href="../ch26/ch26-05.html"><strong aria-hidden="true">26.5.</strong> Zero-One Boxes</a></li><li class="chapter-item expanded "><a href="../ch26/ch26-06.html"><strong aria-hidden="true">26.6.</strong> The t-TEST</a></li><li class="chapter-item expanded "><a href="../ch26/ch26-07.html"><strong aria-hidden="true">26.7.</strong> Revew Exercises</a></li><li class="chapter-item expanded "><a href="../ch26/ch26-08.html"><strong aria-hidden="true">26.8.</strong> Summary</a></li></ol></li><li class="chapter-item expanded "><a href="../ch27/ch27.html"><strong aria-hidden="true">27.</strong> More Tests for Averages</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../ch27/ch27-01.html"><strong aria-hidden="true">27.1.</strong> The Standard Error for a Difference</a></li><li class="chapter-item expanded "><a href="../ch27/ch27-02.html"><strong aria-hidden="true">27.2.</strong> Comparing Two Sample Averages</a></li><li class="chapter-item expanded "><a href="../ch27/ch27-03.html" class="active"><strong aria-hidden="true">27.3.</strong> Experiments</a></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">28.</strong> </div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">29.</strong> </div></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Statistics</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="experiments"><a class="header" href="#experiments">Experiments</a></h1>
<p>Phương pháp của Mục 2 cũng có thể được sử dụng để phân tích một số loại dữ liệu thực nghiệm nhất định, trong đó các nhà điều tra chọn ngẫu nhiên một số đối tượng nhận điều trị &quot;A&quot; và những đối tượng khác được nhận &quot;B&quot;. Ví dụ, trong thử nghiệm thực địa vắc xin Salk, phương pháp điều trị A sẽ là vắc xin; điều trị B, nhóm đối chứng dùng giả dược (Chương 1). Chúng ta bắt đầu bằng một ví dụ để minh họa cơ chế và sau đó giải thích lý do tại sao phương pháp này hoạt động.</p>
<p><em>Ví dụ 4.</em> Có 200 đối tượng trong một thử nghiệm lâm sàng nhỏ về vitamin C. Một nửa số đối tượng được chỉ định ngẫu nhiên vào nhóm điều trị (2.000 mg vitamin C mỗi ngày) và một nửa vào nhóm đối chứng (2.000 mg giả dược). Trong suốt thời gian thử nghiệm, nhóm điều trị bị cảm lạnh trung bình 2.3 lần và <code>SD</code> là 3.1. Nhóm đối chứng còn tệ hơn một chút: họ có trung bình 2.6 lần cảm lạnh và <code>SD</code> là 2.9. Sự khác biệt về giá trị trung bình có ý nghĩa thống kê không?</p>
<p><em>Giải pháp.</em> Sự khác biệt giữa hai mức trung bình là −0.3 và bạn cần đặt <code>standard error</code> cho con số này. Chỉ cần giả vờ rằng bạn có hai mẫu độc lập được lấy ngẫu nhiên có thay thế. <code>SE</code> của tổng điều trị là \(\sqrt{100} \times 3.1 = 31\); <code>SE</code> của mức trung bình điều trị là \(31/100 = 0.31\). Tương tự, <code>SE</code> cho mức trung bình đối chứng là 0.29. <code>SE</code> cho sự chênh lệch là</p>
<p>\[
\sqrt{0.31^2 + 0.29^2} \approx 0.42
\]</p>
<p>Giả sử <code>null hypothesis</code> đúng: vitamin C không có tác dụng. Trên cơ sở này, <code>expected value</code> của chênh lệch là 0.0. Sự chênh lệch quan sát được là −0.3. Do đó</p>
<p>\[
z = \frac{\text{observed difference - expected difference}}{\text{SE for difference}} = \frac{-0.3 - 0.0}{0.42} \approx -0.7
\]</p>
<p>Sự chênh lệch có thể dễ dàng là do sự ngẫu nhiên: có quá nhiều người dễ bị tổn thương được xếp vào nhóm đối chứng.<sup class="footnote-reference"><a href="#9">1</a></sup></p>
<p>Bây giờ, hãy nhìn vào hậu trường. Khi làm ví dụ này, bạn được yêu cầu giả vờ rằng các mẫu điều trị và đối chứng được lấy độc lập, ngẫu nhiên có thay thế, từ hai hộp. Tuy nhiên, thí nghiệm đã không được thực hiện theo cách đó. Có 200 đối tượng; 100 người được chọn ngẫu nhiên - không thay thế - để nhận vitamin C; 100 người còn lại dùng giả dược. Vì vậy, các lần rút được thực hiện không thay thế. Hơn nữa, các mẫu phụ thuộc. Ví dụ, một đối tượng có thể khá dễ bị cảm lạnh. Nếu đối tượng này thuộc nhóm vitamin C thì anh ta không thể thuộc nhóm giả dược. Do đó, việc phân công ảnh hưởng đến cả hai mức trung bình.</p>
<p>Tại sao <code>SE</code> lại hoạt động bình thường, bất chấp những vấn đề này? Lý do phụ thuộc vào mô hình hộp. Các nhà điều tra đang tiến hành một thử nghiệm. Họ chọn ngẫu nhiên một nhóm đối tượng để nhận điều trị A và một nhóm khác để nhận điều trị B. Như thường lệ, mô hình có một phiếu cho từng đối tượng. Nhưng bây giờ vé có hai số. Một cho thấy phản ứng sẽ như thế nào đối với phương pháp điều trị A; cái còn lại, đối với phương pháp điều trị B. Xem Hình 1. Chỉ có thể quan sát được một trong hai con số, bởi vì đối tượng chỉ có thể được áp dụng một trong hai phương pháp điều trị.</p>
<p><strong><center>Hình 1. Một thí nghiệm đối chứng ngẫu nhiên so sánh phương pháp điều trị A và B. Có một phiếu cho mỗi đối tượng. Phiếu có hai số: một số thể hiện phản ứng của đối tượng với phương pháp điều trị A; còn lại là điều trị B. Chỉ có thể quan sát được một trong hai con số.</center></strong></p>
<center><img src="fig1.png" width="70%" height="auto"></center>
<p>Trong mô hình, một số phiếu được rút ngẫu nhiên không thay thế từ hộp và quan sát thấy phản ứng với cách xử lý A. Dữ liệu về phương pháp điều trị A giống như đợt phản hồi đầu tiên này. Sau đó, nhiều lần rút ngẫu nhiên hơn được thực hiện không thay thế từ hộp và quan sát thấy phản ứng với cách xử lý B. Dữ liệu về phương pháp điều trị B giống như đợt phản hồi thứ hai này. Trong Ví dụ 4, mỗi người trong số 200 đối tượng được chỉ định dùng vitamin C hoặc dùng giả dược. Trong trường hợp như vậy, mẫu thứ hai chỉ bằng số phiếu còn lại trong hộp sau khi mẫu đầu tiên được rút ra.</p>
<p><code>null hypothesis</code> cho rằng phản ứng giống nhau đối với cả hai phương pháp điều trị.<sup class="footnote-reference"><a href="#10">2</a></sup> Để kiểm tra giả thuyết này, các nhà điều tra thường so sánh mức trung bình (hoặc phần trăm):</p>
<p>\[
\text{average response in group A - average response in group B}
\]</p>
<p><code>SE</code> cho sự chênh lệch này là gì? Giải pháp cho Ví dụ 4 dường như liên quan đến hai sai lầm được đề cập trước đó</p>
<ul>
<li>Các lần rút được thực hiện không thay thế, nhưng các <code>SE</code> được tính toán như khi rút có thay thế.</li>
<li>Hai giá trị trung bình này phụ thuộc vào nhau nhưng các <code>SE</code> được kết hợp với nhau như thể trung bình là độc lập.</li>
</ul>
<p>Khi số lần rút ít so với số phiếu trong hộp thì không có sai sót nào nghiêm trọng. Có rất ít sự khác biệt giữa lần rút có hoặc không thay thế, và sự phụ thuộc giữa các mức trung bình cũng rất nhỏ. Gần như có hai hộp riêng biệt, một hộp dành cho nhóm điều trị và một hộp dành cho nhóm đối chứng. Tuy nhiên, mô hình &quot;hai hộp&quot; không thực tế đối với một thử nghiệm ngẫu nhiên có kiểm soát - trừ khi các đối tượng thực sự được chọn làm mẫu ngẫu nhiên từ một quần thể lớn. Điều đó thật bất thường, mặc dù bài tập 8 (tr. 520) đưa ra một ví dụ.</p>
<p>Nếu số lần rút lớn so với kích thước của hộp - và đây là trường hợp thông thường - thì bản thân tác động của mỗi sai sót có thể rất đáng kể. Ví dụ, khi một nửa số đối tượng được phân vào mỗi nhóm điều trị, như trong Ví dụ 4, hệ số hiệu chỉnh sẽ nhỏ hơn đáng kể 1 (<a href="../ch20/ch20-04.html">Mục 20.4</a>). Sự phụ thuộc cũng có thể mạnh. Điều may mắn là khi áp dụng cho các thử nghiệm ngẫu nhiên, quy trình của Mục 2 mang tính thận trọng, có xu hướng đánh giá quá cao <code>SE</code> một lượng nhỏ. Đó là vì hai sai sót bù đắp cho nhau.</p>
<ul>
<li>Sai sót đầu tiên thổi phồng <code>SE</code>.</li>
<li>Sai sót thứ hai khiến <code>SE</code> lùi lại.</li>
</ul>
<blockquote>
<p>Có một hộp. Mỗi phiếu có hai số. Một cho thấy phản ứng sẽ như thế nào đối với phương pháp điều trị A; còn lại là điều trị B. Chỉ có thể quan sát được một trong các con số. Một số phiếu được rút ngẫu nhiên không thay thế từ hộp. Trong mẫu này, quan sát phản ứng với phương pháp điều trị A. Sau đó, mẫu thứ hai được rút ngẫu nhiên không thay thế các phiếu còn lại. Trong mẫu thứ hai, quan sát phản ứng với phương pháp điều trị B.</p>
<p><code>SE</code> cho sự chênh lệch giữa hai giá trị trung bình mẫu có thể được ước tính một cách thận trọng như sau:</p>
<ol>
<li>tính <code>SE</code> cho các giá trị trung bình như thể các phép rút được thực hiện có thay thế;</li>
<li>kết hợp các <code>SE</code> như thể các mẫu độc lập.</li>
</ol>
</blockquote>
<p>Để làm cho phép toán hoạt động, <code>SE</code> cho hai giá trị trung bình mẫu phải được tính trên cơ sở rút CÓ thay thế- mặc dù các lần rút được thực hiện KHÔNG thay thế. Đó là điều bù đắp cho sự phụ thuộc giữa hai mẫu.<sup class="footnote-reference"><a href="#11">3</a></sup> Tóm lại: khi dữ liệu đến từ một thử nghiệm ngẫu nhiên (như ví dụ 4), quy trình ở Mục 2 có thể được sử dụng ngay cả khi có sự phụ thuộc.</p>
<hr />
<div class="footnote-definition" id="9"><sup class="footnote-definition-label">1</sup>
<p>For references to real trials on vitamin C, with interesting sidelights on blinding the randomization, see note 12, chapter 2.</p>
</div>
<div class="footnote-definition" id="10"><sup class="footnote-definition-label">2</sup>
<p>A weaker version of the null is sometimes used: the average response is the same for both treatments. With the strict null, there is really only one number for each ticket (copied into both fields). The strict null is appropriate in many cases, and always has the charm of simplicity. However, the weak null may be more realistic if the new treatment hurts some subjects but helps others. Moreover, some alternative hypotheses do seem to require two numbers for each subject, one for the response to treatment and one for the response to placebo. The discussion continues in note 11.</p>
</div>
<div class="footnote-definition" id="11"><sup class="footnote-definition-label">3</sup>
<p>Consider a clinical trial to compare treatments A and B. We consider the weak form of the null, as in note 10; and the alternative, which does not constrain the responses at all. Suppose there are N subjects, indexed by \(i = 1,..., N\). Let \(x_i\) be the response of subject i to treatment A; likewise, \(y_i\) is the response to B. For each i, either \(x_i\) or \(y_i\) can be observed, but not both. Let
\[
\begin{align*}
\bar{x} &amp;= \frac{1}{N}\sum_{i=1}^{N}x_i     &amp;    \bar{y} &amp;= \frac{1}{N}\sum_{i=1}^{N}y_i\\
\sigma^2 &amp;= \frac{1}{N}\sum_{i=1}^{N}(x_i - \bar{x})^2  &amp;  \tau^2 &amp;=  \frac{1}{N}\sum_{i=1}^{N}(y_i - \bar{y})^2
\end{align*}\\
cov(x,y) = \frac{1}{N}\sum_{i=1}^{N}(x_i - \bar{x})(y_i - \bar{y})
\]<br />
This model is sufficiently flexible to handle the weak form of the null hypothesis (note 10), as well as subject-to-subject heterogeneity under the alternative hypothesis. Thus, for instance, the average difference between treatments A and B—averaged over all the subjects in the study is \(\bar{x} − \bar{y}\). This “average causal effect” measures the difference between putting all the subjects into regime A, or putting all of them into regime B. The average causal effect is often the key parameter. And it is estimable, although the two responses are not simultaneously observable for any individual subject. Indeed, \(\bar{x}, \bar{y}, \sigma^2,\text{ and }\tau^2\) are all estimable; on the other hand, \(cov(x, y)\) cannot be estimated by a sample covariance.<br />
Responses in treatment and control are often modeled, for instance, as independent binomialwith two different \(p\)'s, or independent normals with two different \(\mu\)'s. These parametric modelsseem less realistic. Independence of the two sample averages is generally wrong, and there is noreason to assume subjects are exchangeable within each treatment group. Such assumptions arenot secured by randomization, which only makes the two groups comparable as groups. Thus,theoretical underpinnings are absent for, e.g., the t-test. It is surprising—and reassuring—thatthe permutation distributions of the conventional test statistics more or less coincide with themodel-based distributions, at least in the contexts we are considering.<br />
We now compute the variance of \(\bar{X} − \bar{Y}\) under the alternative hypothesis, in our permutationsetup. Let S be a random subset of \({1,..., N}\), with n elements; this group gets treatment A, so \(x_i\) is observed for \(i \in S\). Let T be a random subset of \({1,..., N}\), with m elements, disjoint from S. This group gets treatment B, so \(y_j\) is observed for \(j \in T\) . We estimate the population means \(\bar{x}\) and \(\bar{y}\) by the sample means
\[
\bar{X} = \frac{1}{n}\sum_{i \in S}x_i \quad \bar{Y} = \frac{1}{m}\sum_{j \in T}y_i
\]
By combinatorial calculations,
\[
var \bar{X} = \frac{N - n}{N - 1} \frac{\sigma^2}{n} \quad var \bar{Y} = \frac{N - m}{N - 1}\frac{\tau^2}{m}\\
cov(\bar{X},\bar{Y}) = -\frac{1}{N - 1}cov(x,y)
\]
Thus
\[
\begin{align*}
var(\bar{X}, \bar{Y}) &amp;= \frac{N - n}{N - 1} \frac{\sigma^2}{n} + \frac{N - m}{N - 1}\frac{\tau^2}{m} + \frac{2}{N - 1}cov(x,y)\\
&amp;= \frac{N}{N - 1}(\frac{\sigma}{n} + \frac{\tau^2}{m}) + \frac{1}{N - 1}[2cov(x,y) - \sigma^2 - \tau^2]\\
&amp;\leq \frac{N}{N - 1}(\frac{\sigma^2}{n} + \frac{\tau^2}{m})
\end{align*}
\]<br />
because \(cov(x, y) \leq \sigma \tau\) and \(2\sigma \tau − \sigma^2 − \tau^2 \leq 0\). The &quot;conservative estimate&quot; in the text is \(\sigma^2/n + \tau^2/m\). In practice, \(\sigma^2\) and \(\tau^2\) would be estimated by sample variances.<br />
The signs may be a little perplexing. In general, we expect x and y to be positively correlated over all subjects. If too many subjects with high x-values are assigned to treatment A, then too few with high y-values are left for B. So the sample averages \(\bar{X}\) and \(\bar{Y}\) are negatively correlated. In principle, \(cov(x, y)\) should be near its upper limit \(\sigma \tau\) , at least when x and y are highly correlated across subjects. Then the &quot;conservative estimate&quot; should be reasonably accurate for large samples. The strict null hypothesis in the text specifies that \(x \equiv y\). Then \(\sigma = \tau\) , and thecalculation is exact under the null hypothesis. Also see note 14 below. Of course, if N is largerelative to m and n, then \(\bar{X}\) and \(\bar{Y}\) are nearly independent; again, the &quot;conservative estimate&quot; willbe nearly right.<br />
The impact of other variables may be handled as follows. Let η denote treatment status. Letω denote the state of other variables influencing the response. We assume there is a function f such that the response of subject i to treatment is \(f(i, η, \omega)\). Let \(\rho\) denote the assignment variable:if \(\rho(i) = A\) then subject i is assigned to treatment A, and likewise for B. We assume that \(\rho\) and \(\omega\) are independent: given \(\omega\), the law of \(\rho\) is uniform over all partitions of the subjects into a groupS of cardinality n assigned to A and another group of cardinality m assigned to B. The objectof randomization, blinding, etc. is to secure this assumption. Then our argument can be doneseparately for each \(\omega\), with
\[
\begin{align*}
x_i &amp;= f(i,A,\omega) \quad \text{for } i \in S \\
y_j &amp;= f(j,B,\omega) \quad \text{for } j \in T
\end{align*}
\]
Few experiments are done on random samples of subjects. Instead, there is some initialscreening process. Only subjects who pass the screen are randomized, and these subjects are bestviewed as a sample of convenience. Therefore, some care is needed in setting up the inferenceproblem. In our model, each subject has two potential responses, one to the treatment regimeand one to the control regime. The &quot;population&quot; consists of pairs of responses. Both responsescannot be simultaneously observed for any subject. The experiment generates data not for thewhole population, but for part of it. We observe responses to the treatment regime for subjects inthe treatment group, and responses to the control regime for subjects in the control group. Thestatistical inference is from these observations to parameters characterizing the set of pairs ofresponses for the subjects that are randomized. The inference is not to some larger population ofsubjects—that kind of generalization would not be automatically justified by randomization. Thisis one aspect of Campbell’s distinction between &quot;internal validity&quot; and &quot;external validity:&quot; seeW. R. Shadish, T. D. Cook, W. T. Campbell, <em>Experimental and Quasi-Experimental Designs forGeneralized Causal Inference</em>(Houghton Mifflin, 2002).<br />
We are thinking primarily of experiments where subjects are divided into two random groups. However, similar comments apply if, for instance, subjects are paired by some ad hoc procedure; then a coin is tossed for each pair, choosing one subject for the treatment regime and one for the control regime. Again, the inference is to parameters characterizing the set of possible responses, and is made conditionally on the set of subjects and the pairing.<br />
The model seems to go back to Neyman’s early work on agricultural experiments. Some
references:<br />
J. Neyman, &quot;Sur les applications de la theorie des probabilit ´ es aux experiences agricoles: Essai des principes,” Roczniki Nauk Rolniczki vol. 10 (1923) pp. 1–51, in Polish; English translation by D. Dabrowska and T. Speed, Statistical Science, vol. 5 (1990) pp. 463–80.<br />
H. Scheffe, “Models in the analysis of variance,” ´ Annals of Mathematical Statistics vol. 27 (1956) pp. 251–71.<br />
J. L. Hodges, Jr. and E. Lehmann, Basic Concepts of Probability and Statistics (Holden-Day, 1964, section 9.4; 2nd ed. reprinted by SIAM, 2004).<br />
D. Rubin, “Estimating causal effects of treatments in randomized and nonrandomized studies,” Journal of Educational Psychology vol. 66 (1974) pp.688–701.<br />
J. Robins, “Confidence interval for causal parameters,” Statistics in Medicine vol. 7 (1988) pp. 773–85.<br />
P. Holland, “Causal inference, path analysis, and recursive structural equations models,”<br />
Sociological Methodology 1988, C. Clogg, editor (American Sociological Association, Washington, D.C., Chapter 13.)<br />
L. Dumbgen, &quot;Combinatorial stochastic processes,&quot; Stochastic Processes and their Applications vol. 52 (1994) pp. 75–92.<br />
D. A. Freedman, Statistical Models: Theory and Practice (Cambridge University Press, 2005).<br />
Minor technical issues: (i) The relevant central limit theorem is for sampling without replacement (note 1, chapter 23). (ii) For small samples, the t-distribution may not provide a better approximation than the normal: the assumptions underlying the t-test do not hold.</p>
</div>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../ch27/ch27-02.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../ch27/ch27-02.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->


    </div>
    </body>
</html>
